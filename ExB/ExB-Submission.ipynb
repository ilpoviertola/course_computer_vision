{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision PS (WS21/22)\n",
    "\n",
    "## Exercise sheet B (ExB)\n",
    "\n",
    "**Group members**: *please list all group members here*\n",
    "\n",
    "**Total (possible) points**: 10\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training/testing data with labels\n",
    "import os\n",
    "path_to_files = \"/Users/ilpoviertola/Repositories/computer-vision/teaching/WS2122/CV/PS/ExB\"\n",
    "\n",
    "X_trn = np.load(os.path.join(path_to_files, 'X_trn.npy'))\n",
    "y_trn = np.load(os.path.join(path_to_files, 'y_trn.npy'))\n",
    "X_tst = np.load(os.path.join(path_to_files, 'X_tst.npy'))\n",
    "y_tst = np.load(os.path.join(path_to_files, 'y_tst.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, our labels are `+1` and `-1` (in the lecture for the perceptron, we has `0` and `1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n",
      "[-1  1]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_trn))\n",
    "print(np.unique(y_tst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2)\n",
    "ax1.plot(X_trn[y_trn==-1,0], X_trn[y_trn==-1,1],'.', color='tab:blue')\n",
    "ax1.plot(X_trn[y_trn==+1,0], X_trn[y_trn==+1,1],'.', color='tab:red')\n",
    "ax1.set_title('Training');\n",
    "\n",
    "ax2.plot(X_tst[y_tst==-1,0], X_tst[y_tst==-1,1],'.', color='tab:blue')\n",
    "ax2.plot(X_tst[y_tst==+1,0], X_tst[y_tst==+1,1],'.', color='tab:red')\n",
    "ax2.set_title('Testing');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExB.1 (7 points)\n",
    "\n",
    "Below is pseudocode for the standard perceptron algorithm, formulated slighly different from the lecture,  for labels in $\\{+1,-1\\}$.\n",
    "\n",
    "```\n",
    "w = [0,0]\n",
    "b = 0\n",
    "repeat N times\n",
    "    for (x_i,y_i) in training set\n",
    "        score = <w,x_i> + b\n",
    "        if y_i * score <= 0\n",
    "            w = w + y_i * x_i\n",
    "            b = b + y_i\n",
    "return w\n",
    "```\n",
    "\n",
    "Here `w = [0,0]` denotes $\\mathbf{w} = (0,0)^\\top$, `b=0` is the **bias** term $b$ (which we subsumbed in the lecture into $\\mathbf{w}$). Also, `<w,x_i>` denotes the inner product between $\\mathbf{w}$ and $\\mathbf{x}_i$, i.e., $\\langle \\mathbf{w},\\mathbf{x}_i\\rangle$.\n",
    "\n",
    "The *problem* with this classic variant of the perceptron is that we return the *last* weight vector, i.e., the most recent version. In fact, one could think of each update step as producing a new weight vector (and bias), i.e., a new classifier if you will. At each update, the classifier represents a version specifically tuned to the *last seen sample where an error was made*. The key idea of the **averaged perceptron** is not to return the most recent weight and bias, but to average them across all update steps. Empirically, this typically performs better.\n",
    "\n",
    "A naive incarnation of this **averaged perceptron** algorithm can be written as:\n",
    "\n",
    "```\n",
    "w^{(0)} = [0,0]\n",
    "b^{(0)} = 0\n",
    "t = 0\n",
    "repeat N times\n",
    "    for (x_i,y_i) in training set\n",
    "        score = <w^{(t)},x_i> + b\n",
    "        if y_i * score <= 0\n",
    "            w^{(t+1)} = w^{(t)} + y_i * x_i\n",
    "            b^{(t+1)} = b^{(t)} + y_i\n",
    "        else\n",
    "            w^{(t+1)} = w^{(t+1)}\n",
    "            b^{(t+1)} = b^{(t+1)}\n",
    "        t = t + 1\n",
    "    \n",
    "    return average(w^{(1)},w^{(2)},...,w^{(k)}), average(b^{(1)},b^{(2)},...,b^{(k)})\n",
    "```\n",
    "\n",
    "Here, `w^{(t)}` denotes the weight vector at update step $t$, i.e., $\\mathbf{w}^{(t)}$. Given a training set of size $T$ (i.e., $T$ training tuple of the form $(\\mathbf{x}_i,y_i)$, and $N>0$ iterations, we eventually compute and return the average over $k=N\\cdot T$ weight vectors and bias scalars. Specifically, we have, as our result, \n",
    "\n",
    "$$ \\mathbf{w} = \\frac{1}{N\\cdot T} \\sum_k \\mathbf{w}^{(k)}, \\quad \\text{and} \\quad \n",
    "\\frac{1}{N\\cdot T} \\sum_k b^{(k)}\\enspace.$$\n",
    "\n",
    "Your task is to implement *both* the (1) **original perceptron** and the (2) **averaged perceptron** in a few lines of Python code. *Do not implement your solution as a class as we did in the lecture, unless you really want to*. Finally, assess the training/testing accuracy of both approaches.\n",
    "\n",
    "In terms of points, there are 3 points for the original perceptron and 4 points for the averaged variant.\n",
    "\n",
    "**Note**: stripped down to the bare minimum, this requires not more than 10-15 lines of code. When experimenting, set $N=1000$ for instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Classic perceptron\n",
    "\n",
    "In the perceptron implementation use $\\langle \\mathbf{w},\\mathbf{x}\\rangle + b$, i.e., the variant with explicit bias $b$ (as in the pseudocode). The decision rule then is\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\text{sign}(\\langle \\mathbf{w},\\mathbf{x}\\rangle + b)\n",
    "$$\n",
    "as we have labels in $\\{-1,+1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_ppn(N, X_trn, y_trn):\n",
    "    w = np.zeros((2,)).astype(np.float32) # Initial weight \n",
    "    b = 0                                 # Initial bias\n",
    "\n",
    "    for _ in range(N):\n",
    "        for i in range(X_trn.shape[0]):\n",
    "            score = np.sign(np.dot(w, X_trn[i].reshape(2, 1)) + b)\n",
    "            if y_trn[i] * score <= 0:\n",
    "                w = w + y_trn[i] * X_trn[i]\n",
    "                b = b + y_trn[i]\n",
    "\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Averaged perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_ppn(N, X_trn, y_trn):\n",
    "    w = [np.zeros((2,)).astype(np.float32)] * (X_trn.shape[0] * N + 1)    # Initial weight \n",
    "    b = [0] * (X_trn.shape[0] * N + 1)                                    # Initial bias\n",
    "    t = 0\n",
    "\n",
    "    for _ in range(N):\n",
    "        for i in range(X_trn.shape[0]):\n",
    "            score = np.sign(np.dot(w[t], X_trn[i]) + b[t])\n",
    "            if y_trn[i] * score <= 0:\n",
    "                w[t+1] = w[t] + y_trn[i] * X_trn[i]\n",
    "                b[t+1] = b[t] + y_trn[i]\n",
    "            else:\n",
    "                w[t+1] = w[t]\n",
    "                b[t+1] = b[t]\n",
    "            t = t + 1\n",
    "    \n",
    "    return np.average(w, axis=0), np.average(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III: Evaluation on training/testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights and bias term of classic perceptron model:\n",
      "[9.28379946 2.10318587] -8\n",
      "Weights and bias term of averaging perceptron model:\n",
      "[9.17972241 3.02520916] -7.270653276381766\n",
      "Accuracy of the classic perceptron model:\n",
      "For training data: 0.9 For test data: 0.8\n",
      "Accuracy of averaging perceptron model:\n",
      "For training data: 0.9714285714285714 For test data: 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "def evaluate(X, y, w, b):\n",
    "    X = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "    w = np.hstack((w, b))\n",
    "    pred = np.sign(np.dot(X, w)).reshape(-1)\n",
    "    acc = np.sum(pred == y) / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "N = 1000    # ephocs\n",
    "\n",
    "# Train classifiers\n",
    "w_std, b_std = std_ppn(N, X_trn, y_trn)\n",
    "w_avg, b_avg = avg_ppn(N, X_trn, y_trn)\n",
    "print(\"Weights and bias term of classic perceptron model:\")\n",
    "print(w_std, b_std)\n",
    "print(\"Weights and bias term of averaging perceptron model:\")\n",
    "print(w_avg, b_avg)\n",
    "\n",
    "# Standard perceptron model evaluation\n",
    "acc_std_trn = evaluate(X_trn, y_trn, w_std, b_std)\n",
    "acc_std_tst = evaluate(X_tst, y_tst, w_std, b_std)\n",
    "print(\"Accuracy of the classic perceptron model:\")\n",
    "print(\"For training data:\", acc_std_trn, \"For test data:\", acc_std_tst)\n",
    "\n",
    "# Average perceptron model evaluation\n",
    "acc_avg_trn = evaluate(X_trn, y_trn, w_avg, b_avg)\n",
    "acc_avg_tst = evaluate(X_tst, y_tst, w_avg, b_avg)\n",
    "print(\"Accuracy of averaging perceptron model:\")\n",
    "print(\"For training data:\", acc_avg_trn, \"For test data:\", acc_avg_tst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExB.2 (3 points)\n",
    "\n",
    "Modify the code of the **averaged perceptron** to make it more efficient, i.e., so that you do not have to store **all** weight vectors from **all** $N \\cdot T$ updates.\n",
    "\n",
    "**Hint**: Just think about how the update is actually computed, e.g., take $\\mathbf{w}^{(4)}$:\n",
    "\n",
    "0. $\\mathbf{w}^{(0)} = (0,0)^\\top$\n",
    "1. $\\mathbf{w}^{(1)} = \\mathbf{w}^{(0)} + \\boldsymbol{\\theta}_1 = \\boldsymbol{\\theta}_1 $\n",
    "2. $\\mathbf{w}^{(2)} = \\mathbf{w}^{(1)} + \\boldsymbol{\\theta}_2 = \\boldsymbol{\\theta}_1 + \\boldsymbol{\\theta}_2$\n",
    "3. $\\mathbf{w}^{(3)} = \\mathbf{w}^{(2)} + \\boldsymbol{\\theta}_3 = \\boldsymbol{\\theta}_1 + \\boldsymbol{\\theta}_2 + \\boldsymbol{\\theta}_3$\n",
    "4. $\\mathbf{w}^{(4)} = \\mathbf{w}^{(2)} + \\boldsymbol{\\theta}_4 = \\boldsymbol{\\theta}_1 + \\boldsymbol{\\theta}_2 + \\boldsymbol{\\theta}_3 + \\boldsymbol{\\theta}_4$\n",
    "\n",
    "So, \n",
    "\n",
    "$$ \\frac{\\mathbf{w}^{(1)}+\\mathbf{w}^{(2)}+\\mathbf{w}^{(3)}+\\mathbf{w}^{(4)}}{4}$$\n",
    "can be written as\n",
    "$$ \\frac{4}{4}\\boldsymbol{\\theta}_1 + \\frac{3}{4}\\boldsymbol{\\theta}_2 + \\frac{2}{4}\\boldsymbol{\\theta}_3 + \\frac{1}{4}\\boldsymbol{\\theta}_4$$\n",
    "\n",
    "Essentially, you just need to translate this into code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.1748879   3.0166491  -7.27911268]\n"
     ]
    }
   ],
   "source": [
    "def avg_ppn_mod(N, X_trn, y_trn):\n",
    "    # Weight acerages for every epoch\n",
    "    w_avg = []\n",
    "    w = [np.zeros((3,), dtype=np.float32)]\n",
    "    X_trn = np.hstack((X_trn, np.ones((X_trn.shape[0], 1))))\n",
    "\n",
    "    for _ in range(N):\n",
    "        t = 0\n",
    "        w = [w[-1]] * (1 + X_trn.shape[0])\n",
    "        for i in range(X_trn.shape[0]):\n",
    "            score = np.sign(np.dot(w[t], X_trn[i]))\n",
    "            if y_trn[i] * score <= 0:\n",
    "                w[t+1] = w[t] + y_trn[i] * X_trn[i]\n",
    "            else:\n",
    "                w[t+1] = w[t]\n",
    "            t = t + 1\n",
    "        \n",
    "        w_avg.append(np.average(w, axis=0))\n",
    "    \n",
    "    return np.average(w_avg, axis=0)\n",
    "\n",
    "w = avg_ppn_mod(N, X_trn, y_trn)\n",
    "\n",
    "print(w)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fdc2f73bf5d480b4cf34a598d9b45a8492d840372cfa5913d0a708f31ebf008"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('computer_vision': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
